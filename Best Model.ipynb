{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from smartcar.utils.path import get_data_paths\n",
    "from smartcar.utils.read import read_json_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\Projects\\SmartCar\\data\"\n",
    "image_fnames, label_fnames = get_data_paths(data_dir)\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartCarGenerator(Sequence):\n",
    "    def __init__(self, image_fnames, label_fnames, batch_size, image_shape, shuffle=True):\n",
    "        self.image_fnames = np.array(image_fnames)\n",
    "        self.label_fnames = np.array(label_fnames)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "        if shuffle:\n",
    "            indices = np.array([i for i in range(len(image_fnames))])\n",
    "            indices = np.random.permutation(indices)\n",
    "            self.image_fnames = self.image_fnames[indices]\n",
    "            self.label_fnames = self.label_fnames[indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.ceil(len(image_fnames) / float(self.batch_size)).astype(np.int)\n",
    "                       \n",
    "    def __getitem__(self, idx):\n",
    "        x_fnames = self.image_fnames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        y_fnames = self.label_fnames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        batch_x = np.array([cv2.resize(cv2.imread(path), (self.image_shape[1], self.image_shape[0]), interpolation=cv2.INTER_NEAREST) for path in x_fnames])\n",
    "        return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = SmartCarGenerator(image_fnames, label_fnames, batch_size=16, image_shape=(120, 160, 3), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = datagen.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def augment_brightness(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image1 = np.array(image1, dtype = np.float64)\n",
    "    random_bright = .5 + np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2] * random_bright\n",
    "    image1[:,:,2][image1[:,:,2] > 255]  = 255\n",
    "    image1 = np.array(image1, dtype = np.uint8)\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def build_dataset(datas):\n",
    "    dataset = np.zeros((len(datas), 120, 160, 3))\n",
    "    for i in range(len(datas)):\n",
    "        img = cv2.imread(datas[i])\n",
    "        img = augment_brightness(img)\n",
    "        y1 = int(img.shape[0] / 2)\n",
    "        img = img[y1:, :]\n",
    "        img = cv2.resize(img, (160, 120), interpolation = cv2.INTER_CUBIC)\n",
    "        dataset[i, :, :, :] = img\n",
    "    return dataset\n",
    "\n",
    "def myGenerator(datas, angle_labels, speed_labels, batch=16):\n",
    "    # For each epoch\n",
    "    while 1:\n",
    "        # Suffle datas\n",
    "        indexes_tmp = list(range(len(datas)))\n",
    "        indexes = []\n",
    "        for j in range(3):\n",
    "            indexes += indexes_tmp\n",
    "        shuffle(indexes)\n",
    "        \n",
    "        # For each batch\n",
    "        for i in range(0, len(indexes), batch):\n",
    "            \n",
    "            # Build a batch of datas\n",
    "            batch_data = [datas[indexes[j]] for j in range(i, i + batch) if j < len(indexes)]\n",
    "            y_angle = [angle_labels[indexes[j]] for j in range(i, i + batch) if j < len(indexes)]\n",
    "            y_speed = [speed_labels[indexes[j]] for j in range(i, i + batch) if j < len(indexes)]\n",
    "    \n",
    "            y_angle = np.array(y_angle)\n",
    "            y_speed = np.array(y_speed)\n",
    "            # Build the dataset for the batch\n",
    "            x = build_dataset(batch_data)\n",
    "            \n",
    "            yield x, [y_angle, y_speed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_train = int(nb_data * 0.8)\n",
    "sep_test = nb_data - sep_train\n",
    "gen_train = myGenerator(image_paths[:sep_train], angle_labels[:sep_train], speed_labels[:sep_train], BATCH_SIZE)\n",
    "gen_test = myGenerator(image_paths[sep_train:], angle_labels[sep_train:], speed_labels[sep_train:], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x, y = next(gen_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train, y_train = next(gen_test)\n",
    "print(y_train)\n",
    "for i in range(x_train.shape[0]):\n",
    "    filename = \"train\" + padding_img_id(str(i)) + \".png\"\n",
    "    cv2.imwrite(filename, x_train[i])\n",
    "        #print(filename, y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(angle_labels, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(speed_labels, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnglePredCnn():\n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')                      # First layer, input layer, Shape comes from camera.py resolution, RGB\n",
    "    x = img_in\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)       # 24 features, 5 pixel x 5 pixel kernel (convolution, feauture) window, 2wx2h stride, relu activation\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)       # 32 features, 5px5p kernel window, 2wx2h stride, relu activatiion\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)       # 64 features, 5px5p kernal window, 2wx2h stride, relu\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)       # 64 features, 3px3p kernal window, 2wx2h stride, relu\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)       # 64 features, 3px3p kernal window, 1wx1h stride, relu\n",
    "\n",
    "    # Possibly add MaxPooling (will make it less sensitive to position in image).  Camera angle fixed, so may not to be needed\n",
    "\n",
    "    x = Flatten(name='flattened')(x)                                        # Flatten to 1D (Fully connected)\n",
    "    x = Dense(100, activation='linear')(x)                                    # Classify the data into 100 features, make all negatives 0\n",
    "    x = Dropout(.1)(x)                                                      # Randomly drop out (turn off) 10% of the neurons (Prevent overfitting)\n",
    "    x = Dense(50, activation='linear')(x)                                     # Classify the data into 50 features, make all negatives 0\n",
    "    x = Dropout(.1)(x)                                                      # Randomly drop out 10% of the neurons (Prevent overfitting)\n",
    "    #categorical output of the angle\n",
    "    angle_out = Dense(1, activation='linear', name='angle_out')(x)        # Connect every input with every output and output 15 hidden units. Use Softmax to give percentage. 15 categories and find best one based off percentage 0.0-1.0\n",
    "    \n",
    "    #continous output of throttle\n",
    "    throttle_out = Dense(1, activation='linear', name='throttle_out')(x)      # Reduce to 1 number, Positive number only\n",
    "    #out = Dense(2, activation='linear', name='model_outputs')(x)\n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])#outputs=[out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'mean_squared_error',\n",
    "                        'throttle_out': 'mean_squared_error'},\n",
    "                  #loss={'model_outputs' : 'mean_squared_error'})\n",
    "                  loss_weights={'angle_out': 0.9, 'throttle_out': .001})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnglePredCnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.abspath(\"models/model_aug_bright.h5\")\n",
    "checkpointer = ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "hist = model.fit_generator(generator=gen_train,\n",
    "                           validation_data=gen_test,\n",
    "                           steps_per_epoch=(sep_train * 3 / BATCH_SIZE),\n",
    "                           validation_steps=(sep_test * 3 / BATCH_SIZE),\n",
    "                           epochs=10,\n",
    "                           shuffle=True,\n",
    "                           callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"][1:])\n",
    "plt.plot(hist.history[\"val_loss\"][1:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
