{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from smartcar.utils.path import get_data_paths\n",
    "from smartcar.utils.read import read_json_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\Projects\\SmartCar\\data\"\n",
    "image_fnames, label_fnames = get_data_paths(data_dir)\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartCarGenerator(Sequence):\n",
    "    def __init__(self, image_fnames, label_fnames, batch_size, image_shape, shuffle=True):\n",
    "        self.image_fnames = np.array(image_fnames)\n",
    "        self.label_fnames = np.array(label_fnames)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "        if shuffle:\n",
    "            indices = np.array([i for i in range(len(image_fnames))])\n",
    "            indices = np.random.permutation(indices)\n",
    "            self.image_fnames = self.image_fnames[indices]\n",
    "            self.label_fnames = self.label_fnames[indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.image_fnames) / float(self.batch_size)).astype(np.int)\n",
    "                       \n",
    "    def __getitem__(self, idx):\n",
    "        x_fnames = self.image_fnames[idx * self.batch_size:(idx+1) * self.batch_size]\n",
    "        y_fnames = self.label_fnames[idx * self.batch_size:(idx+1) * self.batch_size]\n",
    "        \n",
    "        batch_x = np.array([\n",
    "            cv2.resize(cv2.imread(path), (self.image_shape[1], self.image_shape[0]), interpolation=cv2.INTER_NEAREST) / 255. for path in x_fnames\n",
    "        ])\n",
    "        batch_y = np.array([read_json_label(path) for path in y_fnames])\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_fnames, label_fnames, train_size=0.80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = SmartCarGenerator(X_train, y_train, batch_size=16, image_shape=(120, 160, 3), shuffle=True)\n",
    "datagen_test = SmartCarGenerator(X_test, y_test, batch_size=16, image_shape=(120, 160, 3), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomCNN():\n",
    "    img_in = Input(shape=(120, 160, 3), name='img_in')                      # First layer, input layer, Shape comes from camera.py resolution, RGB\n",
    "    x = img_in\n",
    "    x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)       # 24 features, 5 pixel x 5 pixel kernel (convolution, feauture) window, 2wx2h stride, relu activation\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)       # 32 features, 5px5p kernel window, 2wx2h stride, relu activatiion\n",
    "    x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)       # 64 features, 5px5p kernal window, 2wx2h stride, relu\n",
    "    x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)       # 64 features, 3px3p kernal window, 2wx2h stride, relu\n",
    "    x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)       # 64 features, 3px3p kernal window, 1wx1h stride, relu\n",
    "\n",
    "    x = Flatten(name='flattened')(x)                                        # Flatten to 1D (Fully connected)\n",
    "    x = Dense(100, activation='linear')(x)                                    # Classify the data into 100 features, make all negatives 0\n",
    "    x = Dropout(.1)(x)                                                      # Randomly drop out (turn off) 10% of the neurons (Prevent overfitting)\n",
    "    x = Dense(50, activation='linear')(x)                                     # Classify the data into 50 features, make all negatives 0\n",
    "    x = Dropout(.1)(x)                                                      # Randomly drop out 10% of the neurons (Prevent overfitting)\n",
    "    #angle_out = Dense(1, activation='linear', name='angle_out')(x)        # Connect every input with every output and output 15 hidden units. Use Softmax to give percentage. 15 categories and find best one based off percentage 0.0-1.0\n",
    "    \n",
    "    #continous output of throttle\n",
    "    #throttle_out = Dense(1, activation='linear', name='throttle_out')(x)      # Reduce to 1 number, Positive number only\n",
    "    out = Dense(2, activation='linear', name='out')(x)\n",
    "    #model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])#outputs=[out])\n",
    "    model = Model(inputs=[img_in], outputs=[out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'out' : 'mean_squared_error'})\n",
    "                  #loss={'angle_out': 'mean_squared_error',\n",
    "                  #      'throttle_out': 'mean_squared_error'},\n",
    "                  #loss_weights={'angle_out': 0.7, 'throttle_out': .3})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "223/248 [=========================>....] - ETA: 2s - loss: 0.0924"
     ]
    }
   ],
   "source": [
    "model_path = os.path.abspath(\"models/test.h5\")\n",
    "checkpointer = ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "hist = model.fit_generator(generator=datagen_train,\n",
    "                           validation_data=datagen_test,\n",
    "                           epochs=10,\n",
    "                           shuffle=True,\n",
    "                           callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"][1:])\n",
    "plt.plot(hist.history[\"val_loss\"][1:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
